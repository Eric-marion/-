{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selenium tutorial\n",
    "### Selenium is a project to test website then be used to scraping because some website need to run javascript. If using what we learned before, we cannot get what we need when the actural content run by javascript.\n",
    "\n",
    "### Install Selenium and it will open a actural browser to do all the jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs('./img/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"http://www.w3.org/TR/html4/strict.dtd\"><html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"zh-CN en\"><head>\n",
      "  <meta charset=\"UTF-8\" />\n",
      "  <meta name=\"vie\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://morvanzhou.github.io/tutorials/data-manipulation/scraping/5-02-scrapy/\")\n",
    "driver.find_element_by_link_text(\"About\").click()\n",
    "driver.find_element_by_link_text(u\"赞助\").click()\n",
    "driver.find_element_by_link_text(u\"教程 ▾\").click()\n",
    "driver.find_element_by_link_text(u\"数据处理 ▾\").click()\n",
    "driver.find_element_by_link_text(u\"网页爬虫\").click()\n",
    "\n",
    "html = driver.page_source       # get html\n",
    "driver.get_screenshot_as_file(\"./img/screenshot1.png\")\n",
    "driver.close()\n",
    "print(html[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 如果不想网页打开被显示出来，所以可以定义出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"http://www.w3.org/TR/html4/strict.dtd\"><html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"zh-CN en\"><head>\n",
      "  <meta charset=\"UTF-8\" />\n",
      "  <meta name=\"vie\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")   # define headless\n",
    "\n",
    "# add the option when creating driver\n",
    "driver = webdriver.Chrome(chrome_options=chrome_options)\n",
    "driver.get(\"https://morvanzhou.github.io/tutorials/data-manipulation/scraping/5-02-scrapy/\")\n",
    "driver.find_element_by_link_text(\"About\").click()\n",
    "driver.find_element_by_link_text(u\"赞助\").click()\n",
    "driver.find_element_by_link_text(u\"教程 ▾\").click()\n",
    "driver.find_element_by_link_text(u\"数据处理 ▾\").click()\n",
    "driver.find_element_by_link_text(u\"网页爬虫\").click()\n",
    "\n",
    "html = driver.page_source    # get html\n",
    "driver.get_screenshot_as_file(\"./img/screenshot2.png\")\n",
    "driver.close()\n",
    "print(html[:200])  # 打印前200个字节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
